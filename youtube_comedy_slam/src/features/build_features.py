#!/usr/bin/env python3

# -*- coding: utf-8 -*-
import argparse

def feature_sum_score(dataset_df, normalized=True):
    """
    This functions creates a score for each video which is the sum(better)-sum(worse)
    :param dataset_df: The dataset panda dataframe
    :return: Normalized series with the final score [-1..1] and the video_id's as index
    """
    better1 = dataset_df[dataset_df.funnier == 'left'].video_id1.sort_index().value_counts()
    better2 = dataset_df[dataset_df.funnier == 'right'].video_id2.sort_index().value_counts()
    better = better1.add(better2, fill_value=0).sort_index()
    worse1 = dataset_df[dataset_df.funnier == 'right'].video_id1.sort_index().value_counts()
    worse2 = dataset_df[dataset_df.funnier == 'left'].video_id2.sort_index().value_counts()
    worse = worse1.add(worse2, fill_value=0).sort_index()
    score = better.subtract(worse, fill_value=0).sort_index()
    if normalized:
        max_score = score.abs().max()
        assert max_score != 0
        score = score / max_score

    return score


def get_corpus_by_video_id(df, dictionary, pbar=None):
    """
    From the df, get all comments by video_id
    :param df: Pandas dataframe containing the downloaded dataset
    :param dictionary: The dictionary as generated by gensim
    :param pbar: tqdm progressbar if applicable
    :return: gensim corpus in bag-of-words
    """
    corpus = []
    df1 = df.groupby('videoId')['textDisplay'].apply(lambda x: "{%s}" % ' '.join(x))
    # Series is returned
    for ind, val in df1.iteritems():
        curbow = dictionary.doc2bow(tokenize(val))
        corpus.append(curbow)
        if not pbar is None:
            pbar.update(1)
    return corpus


if __name__ == '__main__':
    PARSER = argparse.ArgumentParser()
